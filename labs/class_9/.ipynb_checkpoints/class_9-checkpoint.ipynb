{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class 9 \n",
    "\n",
    "# More Pandas : \n",
    "\n",
    "# Time Series \n",
    "\n",
    "As we talked about during last weekâ€™s class Pandas is a very rich package that enables us to conduct many types of analysis, wrangling and visualizations. Working with data, formats like CSVâ€™s , Geojsons and Shapefiles is made easy and so much less intimidating by the use of a few pretty simple command lines! \n",
    "\n",
    "Last week we have seen that functions like summarizing, describing as well as making changes in the initial data are very straight forward in Pandas.\n",
    "\n",
    "Today, we will learn how to use more Pandas' functionalities. We will use these in conjunction with other packages as well as with other Pandas functionalists we used last week. Acknowledging that things are intertwined, in the next few weeks we will build our knowledge of working with different Python packages. We will also use more and more functionalities and commands with time while also using the simple functions. This method will hopefully help us build strong data analytics programming knowledge that you can use in your future academic studies and careers ðŸ“ŠðŸ“ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#runing packages \n",
    "import pandas as pd #<-- we know this one \n",
    "import numpy as np\n",
    "import matplotlib #<-- for viz\n",
    "import matplotlib.pyplot as plt#<-- for viz\n",
    "from datetime import datetime #<-- note this one is for our time series analysis \n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note about the data: the first data we will be working on is about year old, and therefore the number of days and cases is reflected in it. The second data will be the same data as last week (NYT) but updated to a few days ago."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data: \n",
    "\n",
    "Today we will work with a world wide data about COVID-19 from \"Our World in Data: https://ourworldindata.org\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first load all cases csv: \n",
    "\n",
    "all_cases = pd.read_csv('total_cases.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's get some basic info: \n",
    "all_cases.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cases.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 95 rows (days) and rows, which are 205 countries in total "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: \n",
    "\n",
    "## a.\n",
    "    \n",
    " What is the total number of cases in:\n",
    " - Argentina\n",
    " - United Kingdom \n",
    " - Italy \n",
    " - Spain \n",
    " - United States\n",
    " \n",
    "  \n",
    "   \n",
    "   Hint: remember that the last day in this data is April 3rd 2020 and that the data is accumlated day by day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. What is the ratio of total cases between:\n",
    "* Brazil and France \n",
    "* South Africa and United Kingdom "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose the data:\n",
    "# april3T = april3rd.T\n",
    "# april3T[4:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Now let's create some visualizations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first let's start with an overall world trend\n",
    "sns.set(rc={'figure.figsize':(11, 4)})\n",
    "all_cases['World'].plot(linewidth=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the figure size\n",
    "sns.set(rc={'figure.figsize':(10, 8)})\n",
    "#visualize countries:\n",
    "all_cases['Italy'].plot(linewidth=1);\n",
    "all_cases['United States'].plot(linewidth=1);\n",
    "all_cases['Spain'].plot(linewidth=1);\n",
    "all_cases['France'].plot(linewidth=1);\n",
    "all_cases['United Kingdom'].plot(linewidth=1);\n",
    "all_cases['China'].plot(linewidth=1);\n",
    "all_cases['Iran'].plot(linewidth=1);\n",
    "all_cases['Israel'].plot(linewidth=1);\n",
    "all_cases['Canada'].plot(linewidth=1);\n",
    "all_cases['Canada'].plot(linewidth=1);\n",
    "\n",
    "#add legend:\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "#remove the grid and axis \n",
    "plt.axis('off')\n",
    "\n",
    "#add title\n",
    "plt.title('COVID-19 Total number of cases in 10 countries')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series \n",
    "\n",
    "Time series data is a useful form of data for many fields like climate change, finance, and urban informatics as well as many many others! The importance of time series data stems from the value that comes from understanding how things change over time. This temporal dimension means we need to have data that appears in *regular* intervals in order to treat it as time series. In the age of big data we often see data that is recorded (usually by sensors) in very small intervals, every second or every minute. By being able to conduct time series analysis we can smooth the data and understand it on a higher level. \n",
    "\n",
    "\n",
    "To get started with we will first look for the a time stamp in our data. In our data, as well as others the *data* column will be the one to look into. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cases.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, 'date' does seem to be our time column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cases['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now let's check the dtypes for the \"date\" column\n",
    "all_cases.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see ×´date×´ is object type, we'd need to transform it to a datetime format so that Python will know how to read it using time series analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting the ×´Date×´ column into a datetime format\n",
    "Here are some of the Datetime formats for future reference: \n",
    "- %Y four digit year (e.g. 2019)\n",
    "- %y two-digit year  (w.g. 19)\n",
    "- %m two-digit month  (e.g. 03, 05)\n",
    "- %H hour, 24-hour clock (e.g. 23, 00)\n",
    "- %I hour, 12 hour clock (e.g. 11,12)\n",
    "- %M two-digit minute (e.g. 00,59)\n",
    "- %S seconds (e.g. 00,01)\n",
    "- %w weekday as integer (e.g. 0 for sunday)\n",
    "- %U week # (in a year) when Sunday is the 1st day\n",
    "- %W week # (in the year) when Monday is the 1st day in a week\n",
    "- %z UTC time Zone\n",
    "- %F shortcut for %Y-%m-%d which is a very common datetime (e.g. 2020-04-04)\n",
    "- %D shortcus for another common structure: %m/%d/%y (e.g. 04/04/20)\n",
    "\n",
    "Source: Python for Data Analysis by Wes McKinney"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the Datetime package has calender realted functions, for exmaple, it can tell you the time right now:\n",
    "datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can also calculate number of days between two dates: \n",
    "datetime(2020,12,7)-datetime(2019,10,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "looking into our \"date\" column we see that ours is structured as follows: year(4 digits)-month-day. So if we look into the datetime formates above, we see that in Datetime language, we can translate it into: %Y-%m-%d OR %F\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now for us to be able to change the date column into a datetime, we need to understand the format. \n",
    "#let's transform the date column from string into datetime format\n",
    "all_cases['date'] = pd.to_datetime(all_cases['date'], format=\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now let's run this command again and see if our reformating worked\n",
    "all_cases.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see indeed that the \"date\" column has not been changed to a datetime type. \n",
    "\n",
    "\n",
    "Note that time series behaves like any other pandas series so we can do stuff like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cases['date'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cases['date'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cases['date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_cases['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why should we be \"smoothing\" data?\n",
    "\n",
    "One of the reasons time series data is very useful is due to the \"smoothing\" of data. Smoothing a dataset means removing outliers and seeing the general trend rather than the value for each single datapoint or to remove the \"noise\". Smoothing the data helps create data that is easier to use later on for creating predictions becuase it makes patterns more noticable.  \n",
    "\n",
    "There are a few different ways to smooth data. Today we will look into a very common method for smoothing--rolling mean (AKA moving windows). \n",
    "\n",
    "## Rolling Mean\n",
    "\n",
    "Rolling means are a way to calculate **local** averages for the purpose of smoothing the data. \n",
    "\n",
    "In this method, instead of calculating one average for the entire data, the average is calcualted in constant intervals. Using rolling means in time series is very common. The main reason is that timeseries include a large amount of observations. By displaying rolling means instead of the actual data, we can show trends. \n",
    "\n",
    "In statistics, rolling means are used for predictions (e.g. ARIMA). We will not touch upon this topic today. \n",
    "\n",
    "Let's calculate rolling means for our covid data. For covid cases smooothing the data is particularly important, becuase there are many reasons for small fluctuations in the data day-by-day (e.g. some clinics are not open over weekends and holidays and many people tend to go get tested just before holidays if they plan to visit family for example). Therefore, getting a smoother understanding of the trends in the data helps us eliminate some of those biases and human beahviors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's calculate the rolling mean for the United States cases \n",
    "\n",
    "# here I am creating the local mean for intervals of 4 (in our case every 4 days). \n",
    "#In larger datasets we might apply larger intervals \n",
    "all_cases['USrolling_mean'] = all_cases['United States'].rolling(7, center=True).mean()\n",
    "# now let's view our new column  \n",
    "all_cases['USrolling_mean'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's look into the rolling mean column in comparison to the actual cases per data:\n",
    "print ('US cases', all_cases['United States'][30:34])\n",
    "print ('Rolling mean in the US', all_cases['USrolling_mean'][30:34])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that these are both mostly similiar, but that the rolling mean is \"moving\" a little slower. \n",
    "Let's visualize both the number of cases per day and the rolling mean for the US:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(10, 8)})\n",
    "#all_cases['World'].plot(linewidth=0.5);\n",
    "#all_cases['Vietnam'].plot(linewidth=0.5);\n",
    "\n",
    "all_cases['United States'][60:].plot(linewidth=1.5);\n",
    "all_cases['USrolling_mean'][60:].plot(linewidth=1.5);\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.title('US rolling mean and total cases')\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's do the same for other countries\n",
    "all_cases['Italyrolling_mean'] = all_cases['Italy'].rolling(7, center=True).mean()\n",
    "all_cases['Chinarolling_mean'] = all_cases['China'].rolling(7, center=True).mean()\n",
    "all_cases['Iranrolling_mean'] = all_cases['Iran'].rolling(7, center=True).mean()\n",
    "all_cases['UKrolling_mean'] = all_cases['United Kingdom'].rolling(7, center=True).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(15, 8)})\n",
    "\n",
    "\n",
    "#italy\n",
    "all_cases['Italy'][15:].plot(linewidth=1.2, c='red');\n",
    "all_cases['Italyrolling_mean'][15:].plot(linewidth=1.2, c='darkred');\n",
    "\n",
    "#US\n",
    "all_cases['United States'][15:].plot(linewidth=1.2, c='aquamarine');\n",
    "all_cases['USrolling_mean'][15:].plot(linewidth=1.2, c='teal');\n",
    "\n",
    "#uk\n",
    "all_cases['United Kingdom'][15:].plot(linewidth=1.2, c='chocolate');\n",
    "all_cases['UKrolling_mean'][15:].plot(linewidth=1.2, c='peru');\n",
    "\n",
    "#china\n",
    "all_cases['China'][15:].plot(linewidth=1.2, c='lawngreen');\n",
    "all_cases['Chinarolling_mean'][15:].plot(linewidth=1.2, c='lightgreen');\n",
    "\n",
    "#iran\n",
    "all_cases['Iran'][15:].plot(linewidth=1.2, c='plum');\n",
    "all_cases['Iranrolling_mean'][15:].plot(linewidth=1.2, c='indigo');\n",
    "\n",
    "#add title\n",
    "plt.title('Rolling Mean & Total Cases COVID-19')\n",
    "\n",
    "#add legend\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "#remove axis\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that I used two tones of the same color for each country's number of cases and its rolling mean. As the legend indicates, the lighter color is represents the actual cases, and the lighter color represents the rolling mean. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So what is \"moving\" in the rolling mean? \n",
    "\n",
    "The \"moving\" refers to the window width defined by us which is measured by the number of obsservations (days).\n",
    "\n",
    "**One lmitiation with our data is that it shows seasonality (first wave, winter wave etc), which actually is a violation of the rolling mean.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rolling Mean on NYT data\n",
    "Now let's try the same tool for \n",
    "The NYT data we used last week:. Last updated on April 5th\n",
    "https://github.com/nytimes/covid-19-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "US_cases = pd.read_csv('us-states.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "US_cases.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covidNY = US_cases[US_cases['state']== 'New York']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#once again creating a new column to count number of new cases per day\n",
    "new_cases = []\n",
    "previous_count = 0\n",
    "for i in range(len(covidNY.cases)):\n",
    "    current_count = covidNY.cases.iloc[i]\n",
    "    new_cases.append(current_count - previous_count)\n",
    "    previous_count = current_count\n",
    "    \n",
    "#and add it as a column \n",
    "\n",
    "covidNY['new_cases'] = new_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_deaths = []\n",
    "previous_count = 0\n",
    "for i in range(len(covidNY.deaths)):\n",
    "    current_count = covidNY.deaths.iloc[i]\n",
    "    new_deaths.append(current_count - previous_count)\n",
    "    previous_count = current_count\n",
    "    \n",
    "covidNY['new_deaths'] = new_deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covidNY.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: \n",
    "## a. \n",
    "- What was the largest number of cases and deaths in one day in NYS?\n",
    "- In which dates were these numbers recorded? \n",
    "\n",
    "## b. \n",
    "- Which state/s have the largest cumulative number of cases and deaths? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series for NY data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similiar to the world data let's visualize the NY data as time series: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how many days in the data?\n",
    "len(covidNY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tranform data column into datetime\n",
    "#let's transform the date column into datetime format\n",
    "covidNY['date'] = pd.to_datetime(covidNY['date'], format=\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covidNY.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure it works: \n",
    "\n",
    "covidNY['date'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covidNY['NYrolling_mean'] = covidNY['cases'].rolling(4, center=True).mean()\n",
    "covidNY['NYrolling_mean'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize NY rolling mean and total cases: \n",
    "covidNY['NYrolling_mean'].plot(linewidth=0.5);\n",
    "covidNY['cases'].plot(linewidth=0.5);\n",
    "plt.title('NY rolling mean and total cases')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series for Frocasting: \n",
    "\n",
    "Many fields use timeseires analysis for forcasting. That means that looking into a specific period there might be a way to predict the future. That assumes that the \"history repeats itself\". But is that always true? Are the trends we are seeing with COVID-19 cases and deaths are likely to repeat themselves? Given social distanincing and that most of us chaged our lives completly in the past few weeks, we are now still seeing cases and deaths that are likely the result of contamination from 2-3 weeks ago. Another element is that we only have data from 36 days (since the 1st case). 36 days are not enough to really understand trends and being able to predict unsing timeseries analysis. In addition we still can not understand seasonality, which usually is a key to foracsting in timeseries analysis.  \n",
    "\n",
    "To understand this issue even better we will look into both the deaths and the cases' daily counts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for cases "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covidNY['NYrolling_mean_new'] = covidNY['new_cases'].rolling(14, center=True).mean()\n",
    "covidNY['NYrolling_mean_new'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(15, 8)})\n",
    "\n",
    "\n",
    "#\n",
    "covidNY['NYrolling_mean_new'][15:].plot(linewidth=1.2, c='red');\n",
    "covidNY['new_cases'][15:].plot(linewidth=1.2, c='blue');\n",
    "\n",
    "\n",
    "#add title\n",
    "plt.title('Rolling Mean & Total Cases COVID-19 in NYC', c='purple')\n",
    "\n",
    "#add legend\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "#remove axis\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for deaths: \n",
    "\n",
    "covidNY['NYrolling_mean_deaths'] = covidNY['new_deaths'].rolling(14, center=True).mean()\n",
    "covidNY['NYrolling_mean_deaths'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(15, 8)})\n",
    "\n",
    "\n",
    "#\n",
    "covidNY['NYrolling_mean_deaths'][15:].plot(linewidth=1.2, c='purple');\n",
    "covidNY['new_deaths'][15:].plot(linewidth=1.2, c='orange');\n",
    "\n",
    "\n",
    "#add title\n",
    "plt.title('Rolling Mean & Total Deaths COVID-19 in NYC', c='red')\n",
    "\n",
    "#add legend\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "#remove axis\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#covidNY['']\n",
    "\n",
    "covidNY['new_cases'].plot(linewidth=1.5, c='m');\n",
    "#covidNY['new_deaths'].plot(linewidth=1.5, c='C');\n",
    "\n",
    "plt.title('NY daily cases COVID-19')\n",
    "\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.axis('off')\n",
    "#covidNY['cases'].plot(linewidth=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covidNY['new_deaths'].plot(linewidth=1.5, c='C');\n",
    "plt.title('NY daily deaths COVID-19')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: the bigger the data the better! Also, cummulative data isn't helpful for trend detection and time series analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
